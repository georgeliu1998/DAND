{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle OpenStreetMap Data\n",
    "                  by George Liu, December 2015\n",
    "\n",
    "\n",
    "\n",
    "### Overview\n",
    "OpenStreetMap(OSM) is an open map database built by volunteers around the world. The data created are available for free use under the Open Database License (see Appendix for reference). As the data were crowdsourced, there can be inconsistency in how the data is presented. In this project, we will try to improve the data quality with data wrangling and store the cleaned data in MongoDB. In particular, XML map data will be parsed, audited and processed for street type inconsistenty before being reshaped and converted into JSON format data, later imported into the MongoDB database.  \n",
    "\n",
    "Due to page limit, this report only include partial code for the project. The full wrangling script can be found on [GitHub](hhttps://github.com/georgeliu1998/Udacity_Nanodegree).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems in the OSM data\n",
    "In order to prepare the data for adding to the database, specifically, to check the \"k\" value for each tag and to make sure they can be valid keys in MongoDB, we use the \"key_type\" function in the script to examine and get the following result:\n",
    "\n",
    ">{'lower': 2502530, 'lower_colon': 1760581, 'other': 129440, 'problemchars': 0}\n",
    "\n",
    "With **\"lower\"** being tags that contain only lowercase letters and are valid, **\"lower_colon\"** for otherwise valid tags with a colon in their names, **\"problemchars\"** for tags with problematic characters, and **\"other\"** for other tags that do not fall into the other three categories.\n",
    "\n",
    "After running the \"audit_street_type\" function, we are able to find a list of all street types that are not part of our standard unabbreviated street names. For example:\n",
    "> 'Ave': {'455 Mayfair Ave', '480 Mayfair Ave', 'Champlain Ave', 'Raleigh Ave', 'Rawlinson Ave', 'Warden Ave'},\n",
    "\n",
    "> 'Ave.': {'Dean Ave.', 'Islington Ave.', 'University Ave.'},\n",
    "\n",
    "Not only street types can have different forms of abbreviations, such as \"ave.\" versus \"ave\", but also misspelling is not uncommon, \"Driver\" instead of \"Drive\", to cite an example. Based on this, a mapping of problem names to preferred names is built. To fix all this, the \"shape_elemen\" function is run and the resulting data are stored into the final json file that is used to add data to the MongoDB database.\n",
    "\n",
    "One other type of problems is attribute value inconsistency. For example, in some tags, the k attribute value is \"lanes\", and in others, the value is \"lanes : forward\".  This, in itself, may not necessary be a problem. However, when converting to json file, this can cause data structure issues. The problem I encountered was \"TypeError\" in Python when a dictionary was overwritten by the k value with same name. In the previous example, it would be a \"lanes\" dict being replaced as \"lanes\" string, which cannot be added dict items any more.\n",
    "\n",
    "Some \"tag\" tags have \"k\" attribte of \"type\", as a result, this is in conflict with the predefined \"type\" key in the dict(as requested by the instruction of lesson 6 programming exercise). To resovle this, the one corresponding to the overall tag has been renamed to \"tag_type\". \n",
    "\n",
    "Finaly, there're instances where street name has multiple entries concatenated together, such as this one:\n",
    "> 'name': '\\\\2/ Kingston Road, Port Union Road, Sheppard Avenue'\n",
    "\n",
    "And the source for this document is:\n",
    "> 'CanMatrix \\xa9 Department of Natural Resources Canada. All rights reserved.', \n",
    "\n",
    "indicating there is some formatting issue in play that may need to be further cleaned in future project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Overview \n",
    "The data chosen for this project is the OSM Toronto dataset which is downloaded from the Mapzen website. Although the initial downloaded bz2 zip file was only **83,941 KB**, once it was decompressed, the size immediately jumped to **1,216,100 KB**. This new file is named \"toronto_canada.osm\" and has XML format.\n",
    "\n",
    "Using the \"count_tags\" function in the script, the XML file is parsed and tag information is provided in the following output:\n",
    "\n",
    ">defaultdict(int,\n",
    "            {'bounds': 1,\n",
    "             'member': 85911,\n",
    "             'nd': 6085327,\n",
    "             'node': 5452721,\n",
    "             'osm': 1,\n",
    "             'relation': 5713,\n",
    "             'tag': 4392551,\n",
    "             'way': 649048})\n",
    "\n",
    "Then data was processed and saved into a new file \"toronto_canada.osm.json\". This new json format file has a size of **1,491,113 KB**. With this new file, the Toronto OSM data was then added into a MongoDB database named \"osm\", collection \"to\" using following code:\n",
    "\n",
    "> mongoimport --db osm --collection to --file toronto_canada.osm.json\n",
    "\n",
    "Further examination using the \"count_unique\" function gives us the total number of unique users: 1713. This is a little bit more than the result from the following MongoDB query for unique users as some data are removed in the cleaning process due to data integrity problems.\n",
    "\n",
    "From here, we can use the MongoDB Python driver to further explore and summarize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6101769"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "import pprint\n",
    "\n",
    "client = MongoClient('localhost:27017')\n",
    "db = client.osm\n",
    "# Number of documents\n",
    "db.to.find().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5452721"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of nodes\n",
    "db.to.find({\"tag_type\":\"node\"}).count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "649048"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of ways\n",
    "db.to.find({\"tag_type\":\"way\"}).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1296"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of nodes that are cafes\n",
    "db.to.find({\"tag_type\" : \"node\", \"amenity\" : \"cafe\"}).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1695"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of unique users\n",
    "len(db.to.distinct(\"created.user\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'_id': u'andrewpmk', u'count': 4129928},\n",
      " {u'_id': u'MikeyCarter', u'count': 485239},\n",
      " {u'_id': u'Kevo', u'count': 391401}]\n"
     ]
    }
   ],
   "source": [
    "# Top Contributors\n",
    "top10 = db.to.aggregate([{\"$group\" : {\"_id\" : \"$created.user\",\n",
    "                                           \"count\" : {\"$sum\" : 1}}},\n",
    "                              {\"$sort\" : {\"count\" : -1}},\n",
    "                              {\"$limit\" : 10}])\n",
    "pprint.pprint([doc for doc in top10][:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other ideas about the datasets\n",
    "As mentioned previously, there are opportunities to further clean the data. One such example is to audit all the node names (name field of each document), and then try to fix invalid entries and/or standardize the entries. In order to do this, we need to better understand how the information for the fields in question is collected, and to have a \"gold standard\" to verify against. The benefit of doing this type of further cleaning is data quality improvement, which ensures the usefulness of the data - afterall, when data is not correct, queries will be problematic as well. However, more granular cleaning could also lead to more human error, so caution and proper procedures are recommended. \n",
    "\n",
    "In terms of overall process improvement to better the OSM data quality, one potential solution is to implement mandatory fields and automatic data verification at the time of editing. For example, when an OSM user tries to edit the name tag of a node, instead of allowing free entry, maybe some control mechnism can be in place so that it is not allowed to input more than one street names, i.e. with two or more street, avenue or similiar words showing. By doing this, the data quality can be greatly improved at the source. However, the level of efforts involved on the user's part can increase, and may lead to frustration, even less user contribution.\n",
    "\n",
    "The dataset we produced in this project can be used in many ways, including contributing back to OSM to improve data quality, share with local government to better understand city business situation etc.\n",
    "\n",
    "Finally, we run some more queries on the database to further explore this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13%\n"
     ]
    }
   ],
   "source": [
    "# What is the percentage of ways that get updated this year?\n",
    "updated_ways = db.to.find({\"tag_type\" : \"way\", \n",
    "                           \"created.timestamp\" : {\"$regex\" : \"2013.\"}}).count()\n",
    "all_ways = db.to.find({\"tag_type\":\"way\"}).count()\n",
    "print(\"{0:.0f}%\".format(float(updated_ways)/all_ways * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'_id': u'parking', u'count': 25585}]\n"
     ]
    }
   ],
   "source": [
    "# Whic type of amenity is most numerous?\n",
    "amenity = db.to.aggregate([\n",
    "        {\"$match\" : {\"amenity\" : {\"$exists\" : 1}}},\n",
    "        {\"$group\" : {\"_id\" : \"$amenity\",\n",
    "                     \"count\" : {\"$sum\" : 1}}},\n",
    "        {\"$sort\" : {\"count\" : -1}},\n",
    "        {\"$limit\" : 1}\n",
    "    ])\n",
    "pprint.pprint([doc for doc in amenity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.command_cursor.CommandCursor at 0x3f5b0f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are all the amenity types?\n",
    "db.to.aggregate([\n",
    "                 {\"$group\" : {\"_id\" : \"amenity\",\n",
    "                              \"amenity_set\" : {\"$addToSet\" : \"$amenity\"}}\n",
    "                              },\n",
    "                 {\"$sort\" : {\"_id\" : -1}}\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many restuurants are there on Yonge Stree?\n",
    "db.to.find({\"addr.street\" : \"Yonge Street\", \n",
    "            \"amenity\" : \"restaurant\"}).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Where can you find the most Chinese cuisine?\n",
    "chinese_cuisine = db.to.aggregate([\n",
    "        {\"$match\" : {\"amenity\" : \"restaurant\", \n",
    "                     \"cuisine\" : \"chinese\"}},\n",
    "        {\"$group\" : {\"_id\" : \"$address.street\",\n",
    "                     \"count\" : {\"$sum\" : 1}}\n",
    "        },\n",
    "        {\"$sort\" : {\"count\" : -1}},\n",
    "        {\"$limit\" : 10}\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'_id': u'433821981', u'count': 10}]\n"
     ]
    }
   ],
   "source": [
    "# Which nodes get referenced most?\n",
    "most_referred = db.to.aggregate([                     \n",
    "                       {\"$match\" : {\"node_refs\" : {\"$exists\" : 1}}},\n",
    "                       {\"$unwind\" : \"$node_refs\"},\n",
    "                       {\"$group\" : {\"_id\" : \"$node_refs\", \n",
    "                                    \"count\" : {\"$sum\" : 1}}},\n",
    "                       {\"$sort\" : {\"count\" : -1}},\n",
    "                       {\"$limit\" : 1}\n",
    "                     ], allowDiskUse = True)\n",
    "pprint.pprint([n for n in most_referred])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix\n",
    "1. [Full Code of the Project on GitHub](https://github.com/georgeliu1998/Udacity_Nanodegree)\n",
    "2. [OSM Data Download Link](https://mapzen.com/data/metro-extracts)\n",
    "3. [Link to the Map Position Wrangled(Toronto, Canada)](https://www.openstreetmap.org/relation/324211)\n",
    "4. [OpenStreetMap Wikipedia Article](https://en.wikipedia.org/wiki/OpenStreetMap)\n",
    "5. [About Page on OpenStreetMap Site](https://www.openstreetmap.org/about)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
