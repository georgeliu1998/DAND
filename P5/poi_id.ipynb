{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN Percentages:\n",
      "{'bonus': '44%',\n",
      " 'deferral_payments': '73%',\n",
      " 'deferred_income': '66%',\n",
      " 'director_fees': '88%',\n",
      " 'exercised_stock_options': '30%',\n",
      " 'expenses': '35%',\n",
      " 'loan_advances': '97%',\n",
      " 'long_term_incentive': '55%',\n",
      " 'other': '36%',\n",
      " 'poi': '0%',\n",
      " 'restricted_stock': '25%',\n",
      " 'restricted_stock_deferred': '88%',\n",
      " 'salary': '35%',\n",
      " 'total_payments': '14%',\n",
      " 'total_stock_value': '14%'}\n",
      "\n",
      "Data Points that Have NaN's for All Features:\n",
      "['LOCKHART EUGENE E'] \n",
      "\n",
      "features data type: <type 'list'>\n",
      "\n",
      "labels\n",
      "labels data type: <type 'list'>\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "start fitting\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"./tools/\")\n",
    "import pickle\n",
    "import matplotlib.pyplot\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "#######################################\n",
    "### STEP 1: SELECT FEATURES TO USE  ###\n",
    "#######################################\n",
    "\n",
    "#features_list = ['poi', 'salary', 'bonus', 'total_stock_value', 'variable_to_fixed']\n",
    "features_list = ['poi', 'salary', 'deferral_payments', 'total_payments', 'exercised_stock_options',\n",
    "                 'bonus','restricted_stock', 'restricted_stock_deferred', 'total_stock_value',\n",
    "                 'expenses', 'loan_advances', 'other', 'director_fees', 'deferred_income',\n",
    "                 'long_term_incentive']\n",
    "\n",
    "#Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n",
    "\n",
    "\n",
    "###############################\n",
    "### STEP 2: REMOVE OUTLIERS ###\n",
    "###############################\n",
    "\n",
    "# The following code finds the percentages of NaN's in the dataset\n",
    "# Define the function first\n",
    "def calc_nan_percent(feature):\n",
    "    n = 0\n",
    "    for key in data_dict:\n",
    "        if data_dict[key][feature] == 'NaN':\n",
    "            n += 1\n",
    "    percent = '{:.0%}'.format(float(n)/len(data_dict))\n",
    "    return percent\n",
    "\n",
    "# Find out all the finance features that we need to calculate NaN percentage for\n",
    "all_ftrs = data_dict['LAY KENNETH L'].keys()\n",
    "email_ftrs = ['to_messages', 'shared_receipt_with_poi', 'from_messages',\n",
    "              'from_this_person_to_poi', 'email_address', 'from_poi_to_this_person']\n",
    "all_ftrs = [ftr for ftr in all_ftrs if ftr not in email_ftrs]\n",
    "\n",
    "# ['salary', 'deferral_payments', 'total_payments', 'exercised_stock_options', 'bonus',\n",
    "# 'restricted_stock', 'restricted_stock_deferred', 'total_stock_value', 'expenses',\n",
    "# 'loan_advances', 'other', 'poi', 'director_fees', 'deferred_income', 'long_term_incentive']\n",
    "\n",
    "# Calculate the NaN percentages and store in a dict\n",
    "nan_percentage = {}\n",
    "for feature in all_ftrs:\n",
    "    nan_percentage[feature] = calc_nan_percent(feature)\n",
    "\n",
    "# Print the dict\n",
    "print(\"NaN Percentages:\")\n",
    "pprint(nan_percentage)\n",
    "\n",
    "# The following code identifies outliers using visualization\n",
    "\"\"\"\n",
    "data_dict = pickle.load( open(\"../final_project/final_project_dataset.pkl\", \"r\") )\n",
    "features = [\"salary\", \"bonus\"]\n",
    "data_dict.pop('TOTAL', 0)\n",
    "data = featureFormat(data_dict, features)\n",
    "for point in data:\n",
    "    salary = point[0]\n",
    "    bonus = point[1]\n",
    "    matplotlib.pyplot.scatter( salary, bonus )\n",
    "matplotlib.pyplot.xlabel(\"salary\")\n",
    "matplotlib.pyplot.ylabel(\"bonus\")\n",
    "matplotlib.pyplot.show()\n",
    "\"\"\"\n",
    "\n",
    "# Now remove the identified outlier which is the 'TOTAL' data point\n",
    "data_dict.pop('TOTAL', 0)\n",
    "\n",
    "# If a data has zero value for all features, it is not useful, so should be removed as outlier\n",
    "# Identify the data points:\n",
    "zero_keys = []\n",
    "for key in data_dict:\n",
    "    n = 0\n",
    "    for ftr in all_ftrs:\n",
    "        if data_dict[key][ftr] == 'NaN':\n",
    "            n += 1\n",
    "    if n == len(all_ftrs) - 1: # excluding the 'poi' key\n",
    "        zero_keys.append(key)\n",
    "print(\"\\nData Points that Have NaN's for All Features:\")\n",
    "print zero_keys, '\\n'  # 'LOCKHART EUGENE E'\n",
    "\n",
    "# Now remove them\n",
    "for key in zero_keys:\n",
    "    data_dict.pop(key, 0)\n",
    "\n",
    "\"\"\"\n",
    "###################################  \n",
    "### STEP 3: CREATE NEW FEATURES ###\n",
    "###################################    \n",
    " \n",
    "# Store to my_dataset for easy export below.\n",
    "my_dataset = data_dict\n",
    "\n",
    "# Create a new feature \"variable_to_fixed\" which is the ratio of total variable pay\n",
    "# (total stock options plus bonus) to total fixed pay (total payments minus bonus)\n",
    "# The following code takes into acount various scenarios when bonus, total_pay and/or\n",
    "# total_stock is zero and handles correspondingly by changing the formula\n",
    "for key in my_dataset:\n",
    "    bonus = my_dataset[key]['bonus']\n",
    "    total_pay = my_dataset[key]['total_payments']\n",
    "    total_stock = my_dataset[key]['total_stock_value']\n",
    "    if bonus == 'NaN':\n",
    "        bonus = 0\n",
    "    if total_pay == 'NaN':\n",
    "        if total_stock == 'NaN':\n",
    "            my_dataset[key]['variable_to_fixed'] = bonus\n",
    "        else:\n",
    "            my_dataset[key]['variable_to_fixed'] = total_stock + bonus\n",
    "    elif total_stock == 'NaN':\n",
    "        my_dataset[key]['variable_to_fixed'] = float(bonus) / (total_pay - bonus)\n",
    "    else:\n",
    "        my_dataset[key]['variable_to_fixed'] = float(total_stock + bonus) / (total_pay - bonus)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Extract features and labels from dataset for local testing\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "print \"features data type:\", type(features)\n",
    "print \"\\nlabels\"\n",
    "print \"labels data type:\", type(labels)\n",
    "print labels\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "##################################\n",
    "### STEP 4: MAKE THE ESTIMATOR ###\n",
    "##################################\n",
    "\n",
    "# Prepare the pipeline including preprocessing, feature selection and algorithm running\n",
    "# Algorithms: SVC(), LinearSVC(), KNeighborsClassifier(), RandomForestClassifier(), GaussianNB() \n",
    "pipe = make_pipeline(MinMaxScaler(),\n",
    "                     SelectKBest(),\n",
    "                     GaussianNB())\n",
    "\n",
    "params = {#'pca__n_components': [2],\n",
    "          'selectkbest__k': [4],\n",
    "          'selectkbest__score_func': [f_classif],\n",
    "          #'linearsvc__C': [0.1, 1, 10, 100],\n",
    "          #'linearsvc__dual': [False],\n",
    "          #'linearsvc__tol': [0.000001],\n",
    "          #'kneighborsclassifier__n_neighbors': [1, 5],\n",
    "          #'kneighborsclassifier__weights': ['uniform'], \n",
    "          #'kneighborsclassifier__algorithm': ['auto', 'ball_tree'],\n",
    "          #'kneighborsclassifier__leaf_size': [1, 10],\n",
    "          #'svc__C': [0.1, 1, 10, 100],\n",
    "          #'svc__kernel': ['linear', 'rbf'],\n",
    "          #'svc__gamma': [0.001, 0.0001],\n",
    "          #'randomforestclassifier__n_estimators': [5, 10, 20]\n",
    "          }\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features,\n",
    "                                                                            labels,\n",
    "                                                                            test_size=0.2,\n",
    "                                                                            random_state=42)\n",
    "\n",
    "# Make an StratifiedShuffleSplit iterator for cross-validation in GridSearchCV\n",
    "sss = StratifiedShuffleSplit(labels_train,\n",
    "                             n_iter = 20,\n",
    "                             test_size = 0.5,\n",
    "                             random_state = 0)\n",
    "\n",
    "# Make the estimator using GridSearchCV and run cross-validation\n",
    "print 'GridSearching with cross-validation...'\n",
    "clf = GridSearchCV(pipe,\n",
    "                   param_grid = params,\n",
    "                   scoring = 'f1',\n",
    "                   n_jobs = 1,\n",
    "                   cv = sss,\n",
    "                   verbose = 1,\n",
    "                   error_score = 0)\n",
    "\n",
    "\n",
    "#########################################\n",
    "### STEP 5: MODEL FITTING AND TESTING ###\n",
    "#########################################\n",
    "\n",
    "# Fit the model using premade estimator clf\n",
    "clf.fit(features_train, labels_train)\n",
    "\n",
    "# Calculate feature scores\n",
    "scores = clf.best_estimator_.named_steps['selectkbest'].scores_\n",
    "scores = [round(s, 2) for s in scores] #round to 2 decimal points\n",
    "\n",
    "# Combine with features names and rank by score\n",
    "ftr_score = zip(features_list[1:], scores)\n",
    "ftr_score_sorted = sorted(ftr_score,\n",
    "                          key = lambda item: item[1],\n",
    "                          reverse = True) \n",
    "print \"\\nThe Scores for All the Features are:\"\n",
    "pprint(ftr_score_sorted)\n",
    "\n",
    "# Find out the features selected by SelectKBest\n",
    "ftr_index = clf.best_estimator_.named_steps['selectkbest'].get_support()\n",
    "ftrs = [x for x, y in zip(features_list[1:], ftr_index) if y]\n",
    "print \"\\nThe Selected Features Are:\\n\", ftrs \n",
    "\n",
    "# Test the model using the hold-out test data\n",
    "pred = clf.predict(features_test)\n",
    "print '\\n', \"Classification Peformance Report:\"\n",
    "print(classification_report(labels_test, pred))\n",
    "\n",
    "\n",
    "#########################################\n",
    "### STEP 6: GENERATE THE PICKLE FILES ###\n",
    "#########################################\n",
    "\n",
    "dump_classifier_and_data(clf, my_dataset, features_list)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "svc = SVC(kernel=\"linear\")\n",
    "\n",
    "rfecv = RFECV(estimator=svc, step=1, scoring='precision')\n",
    "print 'start fitting'\n",
    "rfecv.fit(features, labels)\n",
    "print 'fitting done'\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "print rfecv.support_\n",
    "features=features[:,rfecv.support_]\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_friedman1\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.svm import SVR\n",
    "X, y = make_friedman1(n_samples=50, n_features=10, random_state=0)\n",
    "estimator = SVR(kernel=\"linear\")\n",
    "selector = RFECV(estimator, step=1, cv=5)\n",
    "selector = selector.fit(X, y)\n",
    "selector.support_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
